---
title: 四：系统设计目标（二）：系统怎样做到高可用
date: 2021-02-10 09:25:39
tags:
- 高并发
- 架构 
category: 高并发
---

#### <font color = "dd0000">高可用性（High Availability， HA）</font>

指系统具备较高的无故障运行的能力。我们再很多开源组件的文档中看到的HA方案就是提升组件可用性，让系统免于宕机无法服务的方案。

比如说Hadoop 1.0中的NameNode是单点的，一旦发生故障则整个集群就会不可用。而再Hadoop 2.0 中提出的NameNode HA方案就是同时开启两个NameNode。
一个处于active状态，一个处于StandBy状态，两者共享存储。一旦Active NameNode发生故障，则可以将StandBy NameNode切换成Active状态继续工作。
这就提升了Hadoop持续无故障运行的能力，也就是他的可用性

### <font color = "dd0000">可用性的度量 </font>

可用性是一个抽象的概念，我们想要度量它，就要知道两个相关的概念， MTBF和MTTR。

MTBF(Mean Time Between Failture)是平均故障间隔，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长系统稳定性越高；

MTTR(Mean Time To Repair)表示故障的平均恢复时间，也可以理解为平均故障时间，这个时间越小表示故障对用户影响越小。

可用性与他们的关系是：

Availability = MTBF/(MTBF + MTTR)

这个比例代表了系统的可用性。一般来说，我们会使用几个九来描述系统的可用性。

<img src="/blog.io/img/系统可用性.png">

其实通过这张图可以发现，一个就和二个九的可用性很容易达到，基本可以通过人肉运维的方式实现。

三个九之后，系统的年故障时间急剧缩减，这个级别的可用性可能就需要建立完善的运维值班体系，故障处理流程和业务变更流程。
你可能还需要在系统设计上有更多的考虑。比如在开发中要考虑，如果发生故障，是否不用人工介入就能自动恢复。同时在工具建设方面也需要更加完善，
以便快速排查问题，恢复系统。

五个九之后就必须需要机器来处理故障了，才会让可用性指标提升一个档次。

一般来说，我们的核心业务系统的可用性要达到四个九，非核心最多容忍三个九。在实际工作中，可能听说过类似的说法，只是不同级别不同业务场景的系统对于可用性要求是不一样的。

### <font color = "dd0000"> 高可用系统的设计思路</font>

一个成熟系统的可用性需要从系统设计和系统运维两方面来做保障，两者共同作用，缺一不可。

1. 系统设计

   <br/>"Design For Failure"是我们做高可用系统设计时秉持的第一原则。在承担百万QPS（
   [吞吐量（TPS）、QPS、并发数、响应时间（RT）概念](https://www.cnblogs.com/data2value/p/6220859.html)
   ）的高并发系统中，集群中机器的数量成百上千台，单机的故障是常态，几乎每一天都有发生故障的可能。

   在做系统设计的时候，要把发生故障作为一个重要的考虑点，预先考虑如何自动化地发现故障，发生故障之后要如何解决。当然了，我们还需要掌握一些具体的优化方法，比如故障转移(failover)、超时控制以及降级和限流。

   一般来说，发生failover的节点可能有两种情况（如mysql的双主热备的两个主服务器）：

   1. 是在完全对等的节点之间做failover。
    2. 是在不对等的节点之间，即系统中存在主节点也存在备节点。
    
   <br/>在对等的节点之间做failover相对来说简单些。在这类系统中所有节点都承担读写流量，并且都不保存状态。每一个节点都可以作为另一个节点的镜像（ZooKeeper？）。
    这种情况一下如果有一个节点挂了，那么随机访问另一个就好了。Nginx就可以配置当某一个Tomcat出现大于500的请求时，重试请求另一个Tomcat节点。
   
   <img src="/blog.io/img/Nginx连接Tomcat.png">

   针对不对等节点的failover机制会复杂很多。比方说我们有一个主节点和很多备用节点，这些备用节点有可能是是热备（同样提供在线服务），也可能是冷备（只是备份使用），
那么我们就需要在代码中控制如何检测主备机器是否故障以及如何做主备切换。
   
   使用最广泛的故障检测机制就是“心跳”。你可以在客户端定期向主节点发送心跳包，也可以从备份节点上定期发送心跳包。如果一段时间内未收到心跳包，如果一段时间内未收到心跳包，
就可以认为主节点挂了。触发选主的操作。
   
   选主的结果需要在多个备份节点上达成一致，所以会使用某一种分布式一致性算法，比如<font color = dddd>Paxos，Raft</font>。

   <br/>除了故障转移意外，对于系统间调用超时的控制也是高可用系统设计的一个重要考虑方面。
   
   复杂的高并发系统会有很多系统模块组成。同时他会依赖很多组件和服务。比如缓存，队列服务等。他们之间的调用最怕的是延迟而不是失败，因为失败通常是瞬时的，
可以通过重试解决。而一旦调用某模块或者应用服务时发生大延迟，调用就会阻塞在这次调用上。它占用的资源得不到释放，当存在大量这样的阻塞的时候，调用发就会因为
   用尽资源而挂掉。
   
   系统开发的初期，超时控制通常不被重视，或者没有方式确定正常的超时时间。
   
   举例来说，一个项目，模块之间通过
   [RPC(Remote Procedure Call)](https://www.zhihu.com/question/25536695)
   框架调用,默认的超时时间是30s。正常情况下运行良好，可是一旦遇到大流量，RPC服务端出现一定数量慢请求的时候，RPC客户端线程就会大量阻塞在这些满请求上长达30s，
   造成RPC客户端用尽调用线程而挂掉。后面开发人员在故障复盘的时候发现这个问题，调整了RPC，数据库，缓存以及第三方服务的超时时间，就不会造成整体系统雪崩。
   
   <br/>那么问题就来了，我们怎么确定超时时间呢？

   如果时间短了，会造成大量错误，对用户体验产生影响；时间长了，又起不到作用。建议时通过收集系统之间的调用日志，统计比如99%的响应时间，然后按照这个时间来定。
如果没有日志，只能靠经验。不论那种，超时时间都不是一成不变的。需要在后面的系统维护过程中不断的修改。
   
   <font color= dd00>超时控制的本质时不让请求一直保持，而是经过一段时间后让请求失败，释放资源给后面的请求使用。</font>这对于用户来说时有损的，但是时必要的。我们还有另外两种有损的方案
能保证系统的可用性，他们就是降级和限流。
   
   <br/>降级是为了保证核心服务的稳定而牺牲非核心的做法。
   
   比如我们发微博会先过反垃圾服务检测，通过后才会完成写数据库等逻辑。反垃圾检测是一个相对较重的操作，
   因为很多的匹配策略，在日常的流量下虽然耗时但还能可以正常相应。但是一旦高并发，它就可能成为瓶颈，因为它不是必须的，所以可以暂时关闭反垃圾，这样就能保证主体的流程更加稳定。
   
   <br/>限流完全时另一种思路，它通过对并发的请求进行限速来保护系统。
   
   比如对于Web应用，我先至单机只能处理每秒1000次请求，超过的部分直接返回错误给客户端。虽然这样的做法损害了用户的体验，但是这在高并发的极端情况下属于
无耐之举，时短暂的行为，因此可以被接受。
   

2. 系统运维

   从灰度发布，故障演练两个方面来考虑如何提升系统的可用性。
   
   1. 灰度发布
   
      在业务平稳运行过程中，系统是很少发生故障的，90%的故障是发生在上线变更阶段的。比如你上了一个新的功能，由于设计方案的问题，数据库的慢请求数翻了一倍，导致系统请求被拖慢而产生故障。

      如果没有变更，数据库怎么会无缘无故地产生那么多的慢请求呢？因此，为了提升系统的可用性，重视变更管理尤为重要。而除了提供必要回滚方案，以便在出现问题时快速回滚恢复之外，另一个主要的手段就是灰度发布。

      灰度发布指的是系统的变更不是一次性地推到线上的，而是按照一定比例逐步推进的。一般情况下，灰度发布是以机器维度进行的。比方说，我们先在10%的机器上进行变更，
      同时观察Dashboard上的系统性能指标以及错误日志。如果运行了一段时间之后系统指标比较平稳并且没有出现大量的错误日志，那么再推动全量变更。
      灰度发布给了开发和运维同学绝佳的机会，让他们能在线上流量上观察变更带来的影响，是保证系统高可用的重要关卡。
      
   2. 故障演练

      故障演练指的是对系统进行一些破坏性的手段，观察在出现局部故障时，整体的系统表现是怎样的，从而发现系统中存在的，潜在的可用性问题。

      一个复杂的高并发系统依赖了太多的组件，比方说磁盘，数据库，网卡等，这些组件随时随地都可能会发生故障。建议你另外搭建一套和线上部署结构一模一样的线下系统，
      然后在这套系统上做故障演练，从而避免对生产系统造成影响。


















